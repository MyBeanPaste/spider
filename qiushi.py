import threadingimport queueimport requestsfrom lxml import etreeimport timeimport randomimport json#采集线程数concurrent = 3#解析线程conparse = 3class parse(threading.Thread):    def __init__(self,num,detail_list,page_thread,f):        super(parse,self).__init__()        self.num = num        self.detail_list = detail_list        self.page_thread = page_thread        self.f = f        self.is_parse = True    def run(self):        print('启动%d号线程'%self.num)        while True:            for t in self.page_thread:                if t.is_alive():                    break            else:                if self.detail_list.qsize() == 0:                    self.is_parse = False            if self.is_parse:                try:                    detail = self.detail_list.get(timeout=3)                except Exception as e:                    detail = None                if detail is not None:                    self.parse(detail)                else:                    break        print('退出%d号线程' %self.num)    def parse(self,detail):        html = etree.HTML(detail)        #获取所有段子div        duanzi_div = html.xpath('//div[@id="content-left"]/div')        for div_list in duanzi_div:            #获取昵称            name = div_list.xpath('./div//h2/text()')[0].replace('\n','')            #获取年龄            age = div_list.xpath('./div//div/text()')            if len(age) > 0:                age = age[0]            else:                age = 0            #获取性别            sex = div_list.xpath('./div//div/@class')            if len(sex) > 0:                if 'women' in sex[0]:                    sex = '女'                else:                    sex = '男'            else:                sex = '中'            #获取段子内容            content = div_list.xpath('.//div[@class="content"]/span/text()')[0].strip()            # 获取好笑数            good_num = div_list.xpath('./div//span[@class="stats-vote"]/i/text()')[0]            # 获取评论            common_num = div_list.xpath('./div//span[@class="stats-comments"]//i/text()')[0]            item = {                'nick':name,                'age': age,                'gender': sex,                'content': content,                'good_num': good_num,                'common_num': common_num,            }            self.f.write(json.dumps(item, ensure_ascii=False) + '\n')#采集线程类class frist(threading.Thread):    def __init__(self,num,page_list,detail_list):        super(frist,self).__init__()        self.num = num        self.page_list = page_list        self.detail_list = detail_list        self.headers = {            "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/61.0.3163.100 Safari/537.36",        }    def run(self):        #输出启动线程信息        print('启动线程%d号'%self.num)        #如果请求队列不为空，则无限续循环，从请求队列里拿请求url        while self.page_list.qsize()>0:            url = self.page_list.get()            print('%d号线程采集：%s'%(self.num,url))            #防止频率过快，随机设置阻塞时间            time.sleep(random.randint(1,3))            #发起http请求获取响应内容，追加到数据队列里，等待解析            response = requests.get(url,headers=self.headers)            if response.status_code == 200:                self.detail_list.put(response.text)def main():    #生成请求队列    page_list = queue.Queue()    #生成数据队列    detail_list = queue.Queue()    f = open('duanzi.json','w',encoding='utf-8')    #循环生成页数    for i in range(1,14):        base_url = "https://www.qiushibaike.com/8hr/page/%d/"%i        page_list.put(base_url)    #生成三个采集线程    page_thread = []    for i in range(concurrent):        t = frist(i+1,page_list,detail_list)        t.start()        page_thread.append(t)    #生成3个解析器    parse_thread = []    for i in range(conparse):        t = parse(i+1,detail_list,page_thread,f)        t.start()        parse_thread.append(t)    for t in page_thread:        t.join()    for t in parse_thread:        t.join()    f.close()if __name__ == '__main__':    main()